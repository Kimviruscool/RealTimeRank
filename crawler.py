import requests
from bs4 import BeautifulSoup
import time
from konlpy.tag import Okt
from collections import Counter
from wordcloud import WordCloud
import matplotlib.pyplot as plt
import platform

# 1. ê³µí†µ í—¤ë” ì„¤ì •
headers = {
    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/110.0.0.0 Safari/537.36'
}


# --- (ê¸°ì¡´ ì‘ì„±í•˜ì‹  í¬ë¡¤ë§ í•¨ìˆ˜ë“¤) ---
def get_naver_news_headlines():
    url = "https://news.naver.com/main/list.naver?mode=LSD&mid=sec&sid1=001"
    data_list = []
    try:
        response = requests.get(url, headers=headers)
        soup = BeautifulSoup(response.text, 'html.parser')
        articles = soup.select('.type06_headline li dl') + soup.select('.type06 li dl')
        for article in articles:
            link_tag = article.select_one('dt:not(.photo) a') or article.select_one('dt.photo a')
            if link_tag:
                title = link_tag.text.strip()
                if title:
                    data_list.append({'source': 'Naver News', 'title': title})
    except Exception as e:
        print(f"âŒ ë„¤ì´ë²„ ë‰´ìŠ¤ ì—ëŸ¬: {e}")
    return data_list


def get_community_best():
    url = "https://gall.dcinside.com/board/lists/?id=dcbest&list_num=100&sort_type=N&search_head=1&page=1"
    data_list = []
    try:
        response = requests.get(url, headers=headers)
        soup = BeautifulSoup(response.text, 'html.parser')
        posts = soup.select('.gall_list .ub-content')
        for post in posts:
            title_tag = post.select_one('.gall_tit a')
            if title_tag:
                title = title_tag.text.strip()
                if title:
                    data_list.append({'source': 'Community', 'title': title})
    except Exception as e:
        print(f"âŒ ì»¤ë®¤ë‹ˆí‹° ì—ëŸ¬: {e}")
    return data_list


# --- 2. ë¶„ì„ ë° ì‹œê°í™” í•¨ìˆ˜ (ìƒˆë¡œ ì¶”ê°€ë¨) ---
def analyze_and_visualize(data_list):
    print("\nâ³ í˜•íƒœì†Œ ë¶„ì„ ë° ì›Œë“œí´ë¼ìš°ë“œ ìƒì„± ì¤‘...")

    okt = Okt()
    noun_list = []

    # 2-1. ë¶ˆìš©ì–´ ë¦¬ìŠ¤íŠ¸ (ë¶„ì„ ê²°ê³¼ ë³´ë©´ì„œ ê³„ì† ì¶”ê°€í•´ì•¼ í•¨)
    stop_words = {'ì†ë³´', 'ì¶©ê²©', 'ì˜¤ëŠ˜', 'ì‹¤ì‹œê°„', 'ê·¼í™©', 'ì´', 'ê·¸', 'ì €', 'ê²ƒ', 'ìˆ˜', 'ë“±', 'ë“¤', 'ì œ', 'ëª…', 'íšŒ', 'ê°œ'}

    for item in data_list:
        title = item['title']
        # ëª…ì‚¬ ì¶”ì¶œ
        nouns = okt.nouns(title)

        for noun in nouns:
            # í•œ ê¸€ì ì œì™¸ ë° ë¶ˆìš©ì–´ ì œì™¸
            if len(noun) > 1 and noun not in stop_words:
                noun_list.append(noun)

    # ë¹ˆë„ìˆ˜ ê³„ì‚°
    count = Counter(noun_list)
    tags = count.most_common(50)  # ìƒìœ„ 50ê°œë§Œ

    if not tags:
        print("âŒ ì¶”ì¶œëœ ëª…ì‚¬ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return

    print("ğŸ”¥ ìƒìœ„ í‚¤ì›Œë“œ TOP 10:", tags[:10])

    # 2-2. í•œê¸€ í°íŠ¸ ì„¤ì • (OSì— ë”°ë¼ ê²½ë¡œê°€ ë‹¤ë¦„)
    if platform.system() == 'Windows':
        font_path = 'C:/Windows/Fonts/malgun.ttf'  # ìœˆë„ìš° ë§‘ì€ê³ ë”•
    elif platform.system() == 'Darwin':
        font_path = '/System/Library/Fonts/AppleGothic.ttf'  # ë§¥ ì• í”Œê³ ë”•
    else:
        font_path = '/usr/share/fonts/truetype/nanum/NanumGothic.ttf'  # ë¦¬ëˆ…ìŠ¤(ë‚˜ëˆ”ê³ ë”•)

    # 2-3. ì›Œë“œí´ë¼ìš°ë“œ ìƒì„±
    wc = WordCloud(
        font_path=font_path,
        background_color='white',
        width=800,
        height=600,
        max_words=50
    )

    # ë¹ˆë„ìˆ˜ ê¸°ë°˜ìœ¼ë¡œ ìƒì„±
    wc.generate_from_frequencies(dict(tags))

    # 2-4. ì´ë¯¸ì§€ ì¶œë ¥
    plt.figure(figsize=(10, 8))
    plt.imshow(wc, interpolation='bilinear')
    plt.axis('off')  # X, Yì¶• ëˆˆê¸ˆ ì œê±°
    plt.show()


# --- ë©”ì¸ ì‹¤í–‰ë¶€ ---
if __name__ == "__main__":
    print("--- ğŸš€ ë°ì´í„° ìˆ˜ì§‘ ì‹œì‘ ---")

    news_data = get_naver_news_headlines()
    time.sleep(1)  # ì°¨ë‹¨ ë°©ì§€ ë”œë ˆì´
    community_data = get_community_best()

    all_data = news_data + community_data

    print(f"âœ… ì´ {len(all_data)}ê°œì˜ ì œëª© ìˆ˜ì§‘ ì™„ë£Œ.")

    # ë¶„ì„ ë° ì‹œê°í™” ì‹¤í–‰
    analyze_and_visualize(all_data)